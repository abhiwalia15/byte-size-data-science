{"cells": [{"metadata": {"collapsed": true}, "cell_type": "markdown", "source": "<IMG SRC=\"https://github.com/jacquesroy/byte-size-data-science/raw/master/images/Banner.png\" ALT=\"BSDS Banner\" WIDTH=1195 HEIGHT=200>"}, {"metadata": {}, "cell_type": "markdown", "source": "# Data Understanding and Preparation\nTo understand data, we need to explore it.\n\nThis adds to the following videos:\n- <a href=\"https://youtu.be/xSDP6u_Xqhc\">017-Spark Data Exploration</a>\n- <a href=\"https://youtu.be/AeeHapnLhyE\">018-Python Pandas Data Exploration</a>\n- <a href=\"https://youtu.be/qw4FtewQFZE\">032-JDBC Data Exploration</a>\n\nThis time, we dig deeper and look at subjects such as:\n- Basic stats\n- Normalization\n- Reducing categorical choices\n- Correlation\n- Visualization \n"}, {"metadata": {}, "cell_type": "markdown", "source": "## 060-Data Understanding and Preparation\nExecute the next cell if you want to see the `Byte Size Data Science` youtube channel video"}, {"metadata": {}, "cell_type": "code", "source": "from IPython.display import IFrame\n\nIFrame(src=\"https://www.youtube.com/embed/vVX8GLEDwoY?rel=0&amp;controls=0&amp;showinfo=0\", width=560, height=315)\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Import the appropriate libraries and set up needed connections"}, {"metadata": {}, "cell_type": "code", "source": "import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport ibm_db\nimport ibm_db_dbi\nimport math\n\nfrom ftplib import FTP\nimport requests, zipfile, io\n\nimport matplotlib.pyplot as plt\n%matplotlib inline", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "credentials = {\n    'username': 'bluadmin',\n    'password': \"\"\"PASSWORD\"\"\",\n    'sg_service_url': 'https://sgmanager.ng.bluemix.net',\n    'database': 'BLUDB',\n    'host': 'dashdb-enterprise-. . . .bluemix.net',\n    'port': '50001',\n    'url': 'https://undefined'\n}\nschema=\"CHICAGO\"", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "dsn = (\n    \"DRIVER={{IBM DB2 ODBC DRIVER}};\"\n    \"DATABASE={0};\"\n    \"HOSTNAME={1};\"\n    \"PORT={2};\"\n    \"PROTOCOL=TCPIP;\"\n    \"SECURITY=ssl;\"\n    \"UID={3};\"\n    \"PWD={4};\").format(credentials['database'], credentials['host'],\n                       credentials['port'], credentials['username'],\n                       credentials['password'])\n\nconn = ibm_db.connect(dsn, \"\", \"\")\npconn = ibm_db_dbi.Connection(conn)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Chicago Accident data\nJust like in the previous videos mentioned above.\n\nThis time, we assume that the data is in a database table as shown in video 059-CSV to DB\n\nThe original data is at: https://github.com/jacquesroy/byte-size-data-science/raw/master/data/ChicagoTrafficCrashes20180917.csv.zip"}, {"metadata": {}, "cell_type": "markdown", "source": "### Staging table definition\n```\nCREATE TABLE CHICAGO.staging_ChicagoAccidents (\n  RD_NO                          VARCHAR(8) NOT NULL PRIMARY KEY,\n  CRASH_DATE_EST_I               CHAR(3),\n  CRASH_DATE                     TIMESTAMP,\n  POSTED_SPEED_LIMIT             INTEGER,\n  TRAFFIC_CONTROL_DEVICE         VARCHAR(23),\n  DEVICE_CONDITION               VARCHAR(24),\n  WEATHER_CONDITION              VARCHAR(22),\n  LIGHTING_CONDITION             VARCHAR(22),\n  FIRST_CRASH_TYPE               VARCHAR(28),\n  TRAFFICWAY_TYPE                VARCHAR(31),\n  LANE_CNT                       INTEGER,\n  ALIGNMENT                      VARCHAR(21),\n  ROADWAY_SURFACE_COND           VARCHAR(15),\n  ROAD_DEFECT                    VARCHAR(17),\n  REPORT_TYPE                    VARCHAR(26),\n  CRASH_TYPE                     VARCHAR(32),\n  INTERSECTION_RELATED_I         CHAR(3),\n  NOT_RIGHT_OF_WAY_I             CHAR(3),\n  HIT_AND_RUN_I                  CHAR(3),\n  DAMAGE                         VARCHAR(13),\n  DATE_POLICE_NOTIFIED           TIMESTAMP,\n  PRIM_CONTRIBUTORY_CAUSE        VARCHAR(80),\n  SEC_CONTRIBUTORY_CAUSE         VARCHAR(80),\n  STREET_NO                      INTEGER,\n  STREET_DIRECTION               CHAR(3),\n  STREET_NAME                    VARCHAR(31),\n  BEAT_OF_OCCURRENCE             INTEGER,\n  PHOTOS_TAKEN_I                 CHAR(3),\n  STATEMENTS_TAKEN_I             CHAR(3),\n  DOORING_I                      CHAR(3),\n  WORK_ZONE_I                    CHAR(3),\n  WORK_ZONE_TYPE                 VARCHAR(12),\n  WORKERS_PRESENT_I              CHAR(3),\n  NUM_UNITS                      INTEGER,\n  MOST_SEVERE_INJURY             VARCHAR(24),\n  INJURIES_TOTAL                 INTEGER,\n  INJURIES_FATAL                 INTEGER,\n  INJURIES_INCAPACITATING        INTEGER,\n  INJURIES_NON_INCAPACITATING    INTEGER,\n  INJURIES_REPORTED_NOT_EVIDENT  INTEGER,\n  INJURIES_NO_INDICATION         INTEGER,\n  INJURIES_UNKNOWN               INTEGER,\n  CRASH_HOUR                     INTEGER,\n  CRASH_DAY_OF_WEEK              INTEGER,\n  CRASH_MONTH                    INTEGER,\n  LATITUDE                       DOUBLE,\n  LONGITUDE                      DOUBLE \n) ORGANIZE BY ROW;\n```"}, {"metadata": {}, "cell_type": "markdown", "source": "## Looking at distinct values"}, {"metadata": {}, "cell_type": "code", "source": "sql = \"\"\"\nSELECT * FROM {0}.staging_ChicagoAccidents LIMIT 2\n\"\"\".format(schema)\ndata_pd = pd.read_sql(sql, pconn)\ndata_pd.head(5)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## How many non null values and distinct values in columns\nThis is something we did in videos 17, 18, and 32. This time, we create an SQL statement programmatically."}, {"metadata": {}, "cell_type": "code", "source": "# Use the column names to create an SQL statement\n# Skip the location column. The fact it is a geometry causes issues with COUNT\nsql = \"SELECT \"\nfor name in data_pd.columns.to_list() :\n    sql = sql + \"count({0}) {1}, count(distinct {0}) {2},\\n\".format(name, name + \"_count\", name + \"_distinct\")\n\nsql = sql[:-2] + \"\\n FROM {0}.staging_ChicagoAccidents\".format(schema)\n\nresult_pd = pd.read_sql(sql, pconn)\nresult_dict = result_pd.iloc[0].to_dict()\n\nfor name in data_pd.columns.to_list() :\n    print(\"{0:30s}COUNT {1:8.0f}\\tDISTINCT {2:8.0f}\".format(name,result_dict[name + '_COUNT'],result_dict[name + '_DISTINCT'] ))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Normalization\nHere, we are talking about relational database normal forms.\n\nWe have multiple columns that are categorical. For example:\n- `TRAFFIC_CONTROL_DEVICE         VARCHAR(23)` - 15 unique values\n- `DEVICE_CONDITION               VARCHAR(24)` -  8 unique values\n- `WEATHER_CONDITION              VARCHAR(22)` -  9 unique values\n- `LIGHTING_CONDITION             VARCHAR(22)` -  6 unique values\n- `FIRST_CRASH_TYPE               VARCHAR(28)` - 15 unique values\n- `TRAFFICWAY_TYPE                VARCHAR(31)` - 11 unique values\n\nWe can create small tables for each categorical column and popiulate them with their unique values.\nThen replace the string in the chicagoAccidents table with a 4-byte integer.\n\nFor example, we would create a `TRAFFIC_CONTROL_DEVICE` table with two columns and 15 rows like:\n\n```\nID  DESCRIPTION\n1\tLANE USE MARKING\n2\tNO CONTROLS\n3\tNO PASSING\n4\tOTHER\n5\tOTHER RAILROAD CROSSING\n```\n\nThen, the ChicagoAccidents column `TRAFFIC_CONTROL_DEVICE` woud be replace by `TRAFFIC_CONTROL_DEVICE_ID`.\n\nThis saves us a lot of storage space and convert our text to a number that is more appropriate for modeling."}, {"metadata": {}, "cell_type": "code", "source": "# Categorical columns that we want to convert into separate tables\ncat_columns = ['TRAFFIC_CONTROL_DEVICE','DEVICE_CONDITION','WEATHER_CONDITION','LIGHTING_CONDITION',\n           'FIRST_CRASH_TYPE','TRAFFICWAY_TYPE','ALIGNMENT','ROADWAY_SURFACE_COND','ROAD_DEFECT',\n           'REPORT_TYPE','CRASH_TYPE','DAMAGE','PRIM_CONTRIBUTORY_CAUSE','SEC_CONTRIBUTORY_CAUSE',\n           'WORK_ZONE_TYPE','MOST_SEVERE_INJURY'\n          ]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "table_def = \"\"\"\nCREATE TABLE {0}.{1}_TABLE (\n    id          INT GENERATED ALWAYS AS IDENTITY\n                    (START WITH 1, INCREMENT BY 1),\n    description VARCHAR(80),\n    group_id    INT DEFAULT -1,\n\n    PRIMARY KEY(id)\n) ORGANIZE BY ROW;\n\"\"\"\n\nfor col in cat_columns :\n    sql = table_def.format(schema,col)\n    cur = pconn.cursor()\n    cur.execute(sql)\n    print(\"Table {0}_TABLE created\".format(col))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "insert_sql = \"\"\"\n  INSERT INTO {0}.{1}_TABLE(description)\n    SELECT distinct {1} AS description \n    FROM CHICAGO.staging_ChicagoAccidents\n\"\"\"\nfor col in cat_columns :\n    sql = insert_sql.format(schema,col)\n    cur = pconn.cursor()\n    cur.execute(sql)\n    print(\"Table {0}_TABLE populated\".format(col))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Reducing categorical choices\nThe posted speed limit has 31 distinct values. We could reduce it in two ways:\n- Remove suspicious values from our analysis\n- Grouping the values"}, {"metadata": {}, "cell_type": "markdown", "source": "## Looking at count per categorical value in each attribute\nWe need to add a few columns that are numeric but still categorical."}, {"metadata": {}, "cell_type": "code", "source": "other_cat_columns = ['POSTED_SPEED_LIMIT','LANE_CNT','NUM_UNITS', 'INJURIES_TOTAL',\n                     'CRASH_HOUR','CRASH_DAY_OF_WEEK','CRASH_MONTH']\ncat_all = cat_columns + other_cat_columns", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Build the SQL statement\nWe need to get all the counts"}, {"metadata": {}, "cell_type": "code", "source": "# Do the same thing but with Quries to the table.\n# I have to build a series of SQL statements and do a UNION ALL on them\n\nquery = \"\"\"\nSELECT '{1}' COLNAME, attr.id COLVALUE, COUNT(*) VALCOUNT\nFROM {0}.staging_ChicagoAccidents acc, {0}.{1}_table attr\nWHERE acc.{1} = attr.description\nGROUP BY '{1}', attr.id \n\"\"\"\n\nquery2 = \"\"\"\nSELECT '{1}' COLNAME, {1} COLVALUE, COUNT(*) VALCOUNT\nFROM {0}.staging_ChicagoAccidents acc\nGROUP BY '{1}', {1}\n\"\"\"\n\nsql = \"\"\nfor name in cat_columns :\n    if (len(sql) > 0 ) :\n        sql = sql + \"UNION ALL\"\n    sql = sql + query.format(schema,name)\nfor name in other_cat_columns :\n    sql = sql + \"UNION ALL\"\n    sql = sql + query2.format(schema,name)\n\nstats_pd = pd.read_sql(sql, pconn)\nprint(\"Number of records: {0}\".format(stats_pd.shape[0]))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Display the graphs"}, {"metadata": {"scrolled": false}, "cell_type": "code", "source": "nb_rows = math.ceil(len(cat_all) / 2)\n\nfig, axes = plt.subplots(nrows=nb_rows, ncols=2)\nfig.set_figheight(75)\nfig.set_figwidth(15)\nfor ix, ax in enumerate(axes.flatten()) :\n    if (ix < len(cat_all) ) :\n        tmp_pd = stats_pd[stats_pd['COLNAME'] == cat_all[ix]].sort_values(by=['COLVALUE'])\n        tmp_pd.plot.bar(ax=ax, x='COLVALUE', y='VALCOUNT',title=cat_all[ix], legend=False)\n        ax.set_xlabel('')\n    else:\n        fig.delaxes(ax)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}
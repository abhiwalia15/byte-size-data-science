{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do word manipulation based on their vector representation\n",
    "We are using GloVe: Global Vectors for Word Representation<br/>\n",
    "from: Jeffrey Pennington,   Richard Socher,   Christopher D. Manning\n",
    "\n",
    "see: https://nlp.stanford.edu/projects/glove/\n",
    "\n",
    "Download the file glove.6B.zip, unzip it, and upload glove.6B.100d.txt into your project assets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gensim\n",
    "To manipulate the vectors, we are using the gensim library.<br/>\n",
    "see: https://pypi.org/project/gensim/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import types\n",
    "import pandas as pd\n",
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "def __iter__(self): return 0\n",
    "\n",
    "# @hidden_cell\n",
    "# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n",
    "# You might want to remove those credentials before you share your notebook.\n",
    "client = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id='9OBEPHS0jj5q0FdEFWpF-USWWwiqFtRkeH6njgVaar',\n",
    "    ibm_auth_endpoint=\"https://iam.bluemix.net/oidc/token\",\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url='https://s3-api.us-geo.objectstorage.service.networklayer.com')\n",
    "\n",
    "# Your data file was loaded into a botocore.response.StreamingBody object.\n",
    "# Please read the documentation of ibm_boto3 and pandas to learn more about your possibilities to load the data.\n",
    "# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n",
    "# pandas documentation: http://pandas.pydata.org/\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.download_file(Bucket='bscstesting-donotdelete-pr-paqxy5fmsmaykn', \n",
    "                     Key='glove.6B.100d.txt', Filename='glove.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 400000 words in this file. You can double-check with thwe following command\n",
    "# !wc -l glove.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The gensim interface expects to have the number of entries and the vectors size as the first line of the file\n",
    "# Add a header to the file: number of rows, and number of dimensions\n",
    "!echo \"400000 100\" >header.txt\n",
    "!cat header.txt glove.txt >glove2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the gensim model using the glove2.txt file\n",
    "# https://radimrehurek.com/gensim/models/keyedvectors.html\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "gmodel=KeyedVectors.load_word2vec_format(\"./glove2.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm *.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(gmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of words: \" + str(len(gmodel.index2word)) )\n",
    "print(\"Vector size: \" + str(gmodel.vector_size) )\n",
    "print(\"First 5 factors of 'computer': \")\n",
    "print(gmodel[\"computer\"][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at similarities\n",
    "See how close two words are from each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"good good: \" + str(gmodel.similarity('good', 'good')) )\n",
    "print(\"good best: \" + str(gmodel.similarity('good', 'best')) )\n",
    "print(\"good bad : \" + str(gmodel.similarity('good', 'bad')) )\n",
    "print(\"good mouse: \" + str(gmodel.similarity('good', 'mouse')) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Related words\n",
    "Find the top 10 related words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms=gmodel.most_similar(positive=['spain'])\n",
    "for x in ms:\n",
    "    print(x[0] + \", \" + str(x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms=gmodel.most_similar(positive=['canada'])\n",
    "for x in ms:\n",
    "    print(x[0] + \", \" + str(x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms=gmodel.most_similar(positive=['although'])\n",
    "for x in ms:\n",
    "    print(x[0] + \", \" + str(x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms=gmodel.most_similar(positive=['computer'])\n",
    "for x in ms:\n",
    "    print(x[0] + \", \" + str(x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word algebra\n",
    "We can do vector algebra to compose words from other words.\n",
    "\n",
    "For example: `\"king\" - \"man\" + \"woman\" = \"queen\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the top choices for results \"king\" - \"man\" + \"woman\"\n",
    "gmodel.most_similar(positive=['king', 'woman'], negative=['man'])[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analogy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "def closest_analogies(\n",
    "    left2: str, left1: str, right2: str, model: KeyedVectors\n",
    ") -> [[float, str]]:\n",
    "    return(model.most_similar(positive=[left1, right2], negative=[left2])[:5])\n",
    "\n",
    "def print_analogy(left2: str, left1: str, right2: str, words: dict) -> None:\n",
    "    analogies = closest_analogies(left2, left1, right2, words)\n",
    "    if (len(analogies) == 0):\n",
    "        print(left2 + \"-\" + left1 + \" is like \" + right2 + \"-?\")\n",
    "    else:\n",
    "        (w, dist) = analogies[0]\n",
    "        print(left2 + \"-\" + left1 + \" is like \" + right2 + \"-\" + w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_analogy('paris', 'france', 'rome', gmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmodel.most_similar(positive=['france', 'rome'], negative=['paris'])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_analogy('man', 'king', 'woman', gmodel)\n",
    "print_analogy('walk', 'walked' , 'go', gmodel)\n",
    "print_analogy('happy', 'sad' , 'rich', gmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least likely word in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmodel.doesnt_match(\"breakfast cereal dinner lunch\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"breakfast dinner: \" + str(gmodel.similarity('breakfast', 'dinner')) )\n",
    "print(\"breakfast lunch: \" + str(gmodel.similarity('breakfast', 'lunch')) )\n",
    "print(\"lunch dinner: \" + str(gmodel.similarity('lunch', 'dinner')) )\n",
    "print(\"breakfast cereal: \" + str(gmodel.similarity('breakfast', 'cereal')) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show a graphical representation of the vectors\n",
    "see: https://stackoverflow.com/questions/43776572/visualise-word2vec-generated-from-gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing only the first 100 words\n",
    "vocab = list(gmodel.vocab)[:100]\n",
    "X = gmodel[vocab]\n",
    "\n",
    "tsne = TSNE(n_components=2)\n",
    "X_tsne = tsne.fit_transform(X[:100,:])\n",
    "# X_tsne = tsne.fit_transform(X)\n",
    "\n",
    "df = pd.DataFrame(X_tsne, index=vocab, columns=['x', 'y'])\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "ax.scatter(df['x'], df['y'])\n",
    "\n",
    "for word, pos in df.iterrows():\n",
    "    ax.annotate(word, pos)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5 with Spark",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{"cells": [{"metadata": {"collapsed": true}, "cell_type": "markdown", "source": "<IMG SRC=\"https://github.com/jacquesroy/byte-size-data-science/raw/master/images/Banner.png\" ALT=\"BSDS Banner\" WIDTH=1195 HEIGHT=200>"}, {"metadata": {}, "cell_type": "markdown", "source": "# Data Understanding and Preparation (part 2)\nTo understand data, we need to explore it.\n\nThis adds to the following videos:\n- <a href=\"https://youtu.be/xSDP6u_Xqhc\">017-Spark Data Exploration</a>\n- <a href=\"https://youtu.be/AeeHapnLhyE\">018-Python Pandas Data Exploration</a>\n- <a href=\"https://youtu.be/qw4FtewQFZE\">032-JDBC Data Exploration</a>\n- <a href=\"https://youtu.be/qw4FtewQFZE\">060-Data Understanding and Preparation</a>"}, {"metadata": {}, "cell_type": "markdown", "source": "## 060-Data Understanding and Preparation\nExecute the next cell if you want to see the `Byte Size Data Science` youtube channel video"}, {"metadata": {}, "cell_type": "code", "source": "from IPython.display import IFrame\n\nIFrame(src=\"https://www.youtube.com/embed/wJQ-5Cm1H0E?rel=0&amp;controls=0&amp;showinfo=0\", width=560, height=315)\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Import the appropriate libraries and set up needed connections\nThere is another library to connect to db2. See: https://pythonhosted.org/ibmdbpy/"}, {"metadata": {}, "cell_type": "code", "source": "import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport ibm_db\nimport ibm_db_dbi\nimport math\n\nfrom ftplib import FTP\nimport requests, zipfile, io\n\nimport matplotlib.pyplot as plt\n%matplotlib inline", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "credentials = {\n    'username': 'bluadmin',\n    'password': \"\"\"PASSWORD\"\"\",\n    'sg_service_url': 'https://sgmanager.ng.bluemix.net',\n    'database': 'BLUDB',\n    'host': 'dashdb-enterprise-. . . .bluemix.net',\n    'port': '50001',\n    'url': 'https://undefined'\n}\nschema=\"CHICAGO\"", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "dsn = (\n    \"DRIVER={{IBM DB2 ODBC DRIVER}};\"\n    \"DATABASE={0};\"\n    \"HOSTNAME={1};\"\n    \"PORT={2};\"\n    \"PROTOCOL=TCPIP;\"\n    \"SECURITY=ssl;\" \n    \"UID={3};\"\n    \"PWD={4};\").format(credentials['database'], credentials['host'],\n                       credentials['port'], credentials['username'],\n                       credentials['password'])\n\nconn = ibm_db.connect(dsn, \"\", \"\")\npconn = ibm_db_dbi.Connection(conn)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Categorical columns that we want to convert into separate tables\ncat_columns = ['TRAFFIC_CONTROL_DEVICE','DEVICE_CONDITION','WEATHER_CONDITION','LIGHTING_CONDITION',\n           'FIRST_CRASH_TYPE','TRAFFICWAY_TYPE','ALIGNMENT','ROADWAY_SURFACE_COND','ROAD_DEFECT',\n           'REPORT_TYPE','CRASH_TYPE','DAMAGE','PRIM_CONTRIBUTORY_CAUSE','SEC_CONTRIBUTORY_CAUSE',\n           'WORK_ZONE_TYPE','MOST_SEVERE_INJURY'\n          ]\nother_cat_columns = ['POSTED_SPEED_LIMIT','LANE_CNT','NUM_UNITS', 'INJURIES_TOTAL',\n                     'CRASH_HOUR','CRASH_DAY_OF_WEEK','CRASH_MONTH']\ncat_all = cat_columns + other_cat_columns", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Get the distribution of each categorical attribute\n### Build the SQL statement\nWe need to get all the counts"}, {"metadata": {}, "cell_type": "code", "source": "# Do the same thing but with Quries to the table.\n# I have to build a series of SQL statements and do a UNION ALL on them\n\nquery = \"\"\"\nSELECT '{1}' COLNAME, attr.id COLVALUE, COUNT(*) VALCOUNT\nFROM {0}.staging_ChicagoAccidents acc, {0}.{1}_table attr\nWHERE acc.{1} = attr.description\nGROUP BY '{1}', attr.id \n\"\"\"\n\nquery2 = \"\"\"\nSELECT '{1}' COLNAME, {1} COLVALUE, COUNT(*) VALCOUNT\nFROM {0}.staging_ChicagoAccidents acc\nGROUP BY '{1}', {1}\n\"\"\"\n\nsql = \"\"\nfor name in cat_columns :\n    if (len(sql) > 0 ) :\n        sql = sql + \"UNION ALL\"\n    sql = sql + query.format(schema,name)\nfor name in other_cat_columns :\n    sql = sql + \"UNION ALL\"\n    sql = sql + query2.format(schema,name)\n\nstats_pd = pd.read_sql(sql, pconn)\nprint(\"Number of records: {0}\".format(stats_pd.shape[0]))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Display the graphs"}, {"metadata": {"scrolled": false}, "cell_type": "code", "source": "nb_rows = math.ceil(len(cat_all) / 2)\n\nfig, axes = plt.subplots(nrows=nb_rows, ncols=2)\nfig.set_figheight(75)\nfig.set_figwidth(15)\nfor ix, ax in enumerate(axes.flatten()) :\n    if (ix < len(cat_all) ) :\n        tmp_pd = stats_pd[stats_pd['COLNAME'] == cat_all[ix]].sort_values(by=['COLVALUE'])\n        tmp_pd.plot.bar(ax=ax, x='COLVALUE', y='VALCOUNT',title=cat_all[ix], legend=False)\n        ax.set_xlabel('')\n    else:\n        fig.delaxes(ax)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Grouping categories\nWe make the following (arbitrary) decisions:\n- TRAFFIC_CONTROL_DEVICE: create 3 groups\n- DEVICE_CONDITION: create 3 groups\n- WEATHER_CONDITION: create 2 groups\n- LIGHTING_CONDITION: create 2 groups\n- FIRST_CRASH_TYPE: create 6 groups\n- TRAFFICWAY_TYPE: create 2 groups\n- ALIGNMENT:ignore this attribute\n- ROADWAY_SURFACE_COND: create 2 groups\n- ROAD_DEFECT: Create 2 groups\n- REPORT_TYPE: keep as-is\n- CRASH_TYPE:keep as-is\n- DAMAGE: keep as-is\n- PRIM_CONTRIBUTORY_CAUSE: create 4 groups\n- SEC_CONTRIBUTORY_CAUSE: create 3 groups\n- WORK_ZONE_TYPE: ignore this attribute\n- MOST_SEVERE_INJURY: ignore this attribute\n- POSTED_SPEED_LIMIT: create 2 groups (30 or other)\n- LANE_CNT: create 3 groups (2, 4, other)\n- NUM_UNITS: ignore this attribute\n- INJURIES_TOTAL: ignore this attribute\n- CRASH_HOUR: keep as-is\n- CRASH_DAY_OF_WEEK: keep as-is\n- CRASH_MONTH: keep as-is"}, {"metadata": {}, "cell_type": "markdown", "source": "## Modify the tables to add a grouping column\nFor the attributes that already have \"side\" tables created, we need to modify them to add a column.<br/>\nThen we need to populate them according to our decisions above."}, {"metadata": {}, "cell_type": "code", "source": "alter_def = \"\"\"\nALTER TABLE {0}.{1}_TABLE ADD COLUMN grouping INTEGER DEFAULT 0\n\"\"\"\n\nfor col in cat_columns :\n    sql = alter_def.format(schema,col)\n    cur = pconn.cursor()\n    cur.execute(sql)\n    print(\"Table {0}_TABLE altered\".format(col))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Add tables for the other columns\nAdd the grouping column right away."}, {"metadata": {}, "cell_type": "code", "source": "table_def = \"\"\"\nCREATE TABLE {0}.{1}_TABLE (\n    id          INT NOT NULL,\n    description INT,\n    grouping    INT default 0,\n\n    PRIMARY KEY(id)\n) ORGANIZE BY ROW;\n\"\"\"\n\nfor col in other_cat_columns :\n    sql = table_def.format(schema,col)\n    cur = pconn.cursor()\n    cur.execute(sql)\n    print(\"Table {0}_TABLE created\".format(col))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Populate the tables\ninsert_sql = \"\"\"\n  INSERT INTO {0}.{1}_TABLE(id,description)\n  SELECT {1}, {1}\n  FROM (\n     SELECT distinct {1} \n     FROM {0}.staging_ChicagoAccidents\n  )\n\"\"\"\nfor col in other_cat_columns :\n    sql = insert_sql.format(schema,col)\n    cur = pconn.cursor()\n    cur.execute(sql)\n    print(\"Table {0}_TABLE populated\".format(col))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Implement our grouping\nWe created the tables with a default value for grouping. That default value would be for \"other\".<br/>\nThis way, we only need to update the exceptions."}, {"metadata": {}, "cell_type": "code", "source": "# The two types of SQL statements we need to execute\nsql = \"\"\"\nUPDATE {0}.{1}_TABLE\nSET grouping = {3}\nWHERE id = {2}\n\"\"\"\nsql2 = \"\"\"\nUPDATE {0}.{1}_TABLE\nSET grouping = id\n\"\"\"", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# TRAFFIC_CONTROL_DEVICE: 15 categories. 12-group1, 13-group2, all others group3\nd = {'id': [12,13], 'grouping': list(range(1,3))}\ncur = pconn.cursor()\nfor ix in range(len(d['id'])) :\n    cur.execute(sql.format(schema,'TRAFFIC_CONTROL_DEVICE',d['id'][ix],d['grouping'][ix]))\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# WEATHER_CONDITION\ncur = pconn.cursor()\nresult = cur.execute(sql.format(schema,'WEATHER_CONDITION',8,1))\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# DEVICE_CONDITION: 8 categories, define 6, 7\nd = {'id': [6,7], 'grouping': [1,2]}\ncur = pconn.cursor()\nfor ix in range(len(d['id'])) :\n    cur.execute(sql.format(schema,'DEVICE_CONDITION',d['id'][ix],d['grouping'][ix]))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# LIGHTING_CONDITION\ncur = pconn.cursor()\nresult = cur.execute(sql.format(schema,'LIGHTING_CONDITION',3,1))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# FIRST_CRASH_TYPE\nd = {'id': [4,7,13,14,15], 'grouping': [1,2,3,4,5]}\ncur = pconn.cursor()\nfor ix in range(len(d['id'])) :\n    cur.execute(sql.format(schema,'FIRST_CRASH_TYPE',d['id'][ix],d['grouping'][ix]))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# TRAFFICWAY_TYPE: create 2 groups \ncur = pconn.cursor()\nresult = cur.execute(sql.format(schema,'TRAFFICWAY_TYPE',9,1))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# ALIGNMENT:ignore this attribute\n# ROADWAY_SURFACE_COND: create 2 groups\ncur = pconn.cursor()\nresult = cur.execute(sql.format(schema,'ROADWAY_SURFACE_COND',2,1))\n# ROAD_DEFECT: Create 2 groups\nresult = cur.execute(sql.format(schema,'ROAD_DEFECT',6,1))\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# REPORT_TYPE: keep as-is\ncur = pconn.cursor()\nresult = cur.execute(sql2.format(schema,'REPORT_TYPE'))\n# CRASH_TYPE:keep as-is\nresult = cur.execute(sql2.format(schema,'CRASH_TYPE'))\n# DAMAGE: keep as-is\nresult = cur.execute(sql2.format(schema,'DAMAGE'))\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# PRIM_CONTRIBUTORY_CAUSE: create 4 groups\nd = {'id': [8,11,22], 'grouping': [1,2,3]}\ncur = pconn.cursor()\nfor ix in range(len(d['id'])) :\n    cur.execute(sql.format(schema,'PRIM_CONTRIBUTORY_CAUSE',d['id'][ix],d['grouping'][ix]))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# SEC_CONTRIBUTORY_CAUSE: create 3 groups\nd = {'id': [30,38], 'grouping': [1,2]}\ncur = pconn.cursor()\nfor ix in range(len(d['id'])) :\n    cur.execute(sql.format(schema,'SEC_CONTRIBUTORY_CAUSE',d['id'][ix],d['grouping'][ix]))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# WORK_ZONE_TYPE: ignore this attribute\n# MOST_SEVERE_INJURY: ignore this attribute\n# POSTED_SPEED_LIMIT: create 2 groups (30 or other)\ncur = pconn.cursor()\nresult = cur.execute(sql.format(schema,'POSTED_SPEED_LIMIT',30,1))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# LANE_CNT: create 3 groups (2, 4, other)\nd = {'id': [2,4], 'grouping': [1,2]}\ncur = pconn.cursor()\nfor ix in range(len(d['id'])) :\n    cur.execute(sql.format(schema,'LANE_CNT',d['id'][ix],d['grouping'][ix]))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# NUM_UNITS: ignore this attribute\n# INJURIES_TOTAL\n# CRASH_HOUR: keep as-is\ncur = pconn.cursor()\nresult = cur.execute(sql2.format(schema,'CRASH_HOUR'))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# CRASH_DAY_OF_WEEK: keep as-is\ncur = pconn.cursor()\nresult = cur.execute(sql2.format(schema,'CRASH_DAY_OF_WEEK'))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# CRASH_MONTH: keep as-is\ncur = pconn.cursor()\nresult = cur.execute(sql2.format(schema,'CRASH_MONTH'))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Correlation\nWe can also get an idea of how numerical attributes relate to each other.\n\nWe could read all the records into a Pandas dataframe and then do the correlation.\nInstead, we use a different interface to the db2 table, **`ibmdbpy`**, to get a reference\nto the table and have the correlation done in the database server.\n\nThis is a lot faster and efficient than reading all the data and then do the correlation."}, {"metadata": {}, "cell_type": "code", "source": "from ibmdbpy import IdaDataBase, IdaDataFrame\n\ndsn2 = 'DASHDB;Database={0};Hostname={1};Port={2};PROTOCOL=TCPIP;SECURITY=ssl;UID={3};PWD={4}'.\\\nformat(credentials['database'], credentials['host'],\n                       credentials['port'], credentials['username'],\n                       credentials['password'])\nidadb = IdaDataBase(dsn=dsn2)\nida_df = IdaDataFrame(idadb, '{0}.STAGING_CHICAGOACCIDENTS'.format(schema))\ncorr_pd = ida_df.corr()\n# idadb.close()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import matplotlib.pyplot as plt\nf = plt.figure(figsize=(12, 12))\nplt.matshow(corr_pd, fignum=f.number)\nplt.xticks(range(corr_pd.shape[1]), corr_pd.columns, fontsize=8, rotation=45)\nplt.yticks(range(corr_pd.shape[1]), corr_pd.columns, fontsize=8)\ncb = plt.colorbar()\ncb.ax.tick_params(labelsize=8)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Create the final table\nFirst, go get the column definitions so we can use the proper data types.\n\nThe column type seems to be followed by a space, we need to accomodate for that. Also, the TIMESTAMP type is listed as TIMESTMP so we need to cover this problem."}, {"metadata": {}, "cell_type": "code", "source": "sql = \"\"\"\nSELECT NAME,COLTYPE,LENGTH,SCALE, NULLS\nFROM SYSIBM.SYSCOLUMNS\nWHERE TBNAME = 'STAGING_CHICAGOACCIDENTS'\nAND   TBCREATOR = '{0}'\nORDER BY COLNO;\n\"\"\".format(schema)\ntabdef_pd = pd.read_sql(sql, pconn)\ntabdef_pd.head(5)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Create the table. This is just helper code where I added the definition of the primary key\n\ncolumn_types = {\"VARCHAR\": \"VARCHAR\", \"CHAR\": \"CHAR\", \"INTEGER\":\"INTEGER\",\"DOUBLE\":\"DOUBLE\", \"TIMESTMP\": \"TIMESTAMP\"}\n\nsql = \"CREATE TABLE {0}.ChicagoAccidents (\\n\".format(schema)\n\nfor row in tabdef_pd.iterrows() :\n    if row[1]['NAME'] in cat_columns :\n        sql = sql + \"  {0:33} INTEGER REFERENCES {1}.{2}_TABLE(ID),\\n\".format(row[1]['NAME'] + \"_ID\",schema,row[1]['NAME'])\n    else :\n        # we need to add the type, length, and if not null\n        sql = sql + \"  {0:33} {1}\".format(row[1]['NAME'],column_types[row[1]['COLTYPE'].strip()] )\n        if row[1]['COLTYPE'].find('CHAR') > -1 :\n            sql = sql + \"({0}) \".format(row[1]['LENGTH'])\n        if row[1]['NULLS'] == 'N' :\n            sql = sql + \"NOT NULL \"\n        sql = sql + \",\\n\"\n\nsql = sql + \"\\n  PRIMARY KEY(RD_NO)\\n) ORGANIZE BY ROW;\"\n# print(sql)\ncur = pconn.cursor()\ncur.execute(sql)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Populate the new table\nWe build the SQL statement programmatically"}, {"metadata": {}, "cell_type": "code", "source": "sql = \"INSERT INTO {0}.ChicagoAccidents \\nSELECT \".format(schema)\n\n# Identify the columns\nfor row in tabdef_pd.iterrows() :\n    if row[1]['NAME'] in cat_columns :\n        sql = sql + \"{0}.{1}_table.id as {1}_ID,\".format(schema,row[1]['NAME'])\n    else :\n        sql = sql + \"{0},\".format(row[1]['NAME'])\n\nsql = sql[:-1] + \"\\n FROM {0}.staging_ChicagoAccidents,\".format(schema)\n\n# Add the other tables\nfor name in cat_columns :\n    sql = sql + \"{0}.{1}_table,\".format(schema,name)\nsql = sql[:-1] + \"\\n WHERE \"\n\n# Add the conditions\nfor name in cat_columns :\n    sql = sql + \"{0}.staging_ChicagoAccidents.{1} = {0}.{1}_table.description\\nAND \".format(schema,name) \nsql = sql[:-4] + \";\"\n\n# print(sql)\ncur = pconn.cursor()\ncur.execute(sql)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}
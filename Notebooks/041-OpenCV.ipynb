{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying OpenCV\n",
    "OpenCV (Open Source Computer Vision Library) is an open source computer vision and machine learning software library.<br/>\n",
    "Being a BSD-licensed product, OpenCV makes it easy for businesses to utilize and modify the code.\n",
    "\n",
    "The library has more than 2,500 optimized algorithms, which includes a comprehensive set of both classic and state-of-the-art computer vision and machine learning algorithms. These algorithms can be used to detect and recognize faces, identify objects, classify human actions in videos, track camera movements, track moving objects, extract 3D models of objects, produce 3D point clouds from stereo cameras, stitch images together to produce a high resolution image of an entire scene, find similar images from an image database, remove red eyes from images taken using flash, follow eye movements, recognize scenery and establish markers to overlay it with augmented reality, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install OpenCV for Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in an image file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the image file we'll be using\n",
    "import sys\n",
    "import types\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "\n",
    "img_name = 'dog.jpg'\n",
    "\n",
    "url = 'https://github.com/jacquesroy/byte-size-data-science/raw/master/data/' + img_name\n",
    "# filename = url.rsplit('/', 1)[-1]\n",
    "urllib.request.urlretrieve(url, img_name)\n",
    "\n",
    "%ls -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "img = plt.imread(img_name)\n",
    "plt.axis('off')\n",
    "plt.title('image')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the model weights\n",
    "This particular model is trained on COCO dataset (common objects in context) from Microsoft.<br/>\n",
    "It is capable of detecting 80 common objects:\n",
    "\n",
    "airplane, apple, backpack, banana, baseball bat, baseball glove, bear, bed, bench, bicycle, bird, boat, book, bottle, bowl, broccoli, bus, <br/>\n",
    "cake, car, carrot, cat, cell phone, chair, clock, couch, cow, cup, dining table, dog, donut, elephant, fire hydrant, fork, frisbee, giraffe, <br/>\n",
    "hair drier, handbag, horse, hot dog, keyboard, kite, knife, laptop, microwave, motorcycle, mouse, orange, oven, parking meter, person, <br/>\n",
    "pizza, potted plant, refrigerator, remote, sandwich, scissors, sheep, sink, skateboard, skis, snowboard, spoon, sports ball, stop sign, <br/>\n",
    "suitcase, surfboard, teddy bear, tennis racket, tie, toaster, toilet, toothbrush, traffic light, train, truck, tv, umbrella, vase, wine glass, <br/>\n",
    "zebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm yolov3.weights yolov3.cfg\n",
    "!wget https://pjreddie.com/media/files/yolov3.weights\n",
    "!wget https://github.com/pjreddie/darknet/raw/master/cfg/yolov3.cfg\n",
    "!ls -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## yolov3.weights: 248MB\n",
    "This means that there are about 62M weights in this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\",\n",
    "\"train\", \"truck\", \"boat\", \"traffic light\", \"fire hydrant\",\n",
    "\"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\", \"dog\",\n",
    "\"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\",\n",
    "\"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\",\n",
    "\"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\", \n",
    "\"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\",\n",
    "\"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\",\n",
    "\"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\",\n",
    "\"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"couch\", \"potted plant\",\n",
    "\"bed\", \"dining table\", \"toilet\", \"tv\", \"laptop\", \"mouse\", \"remote\",\n",
    "\"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\",\n",
    "\"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\",\n",
    "\"hair drier\", \"toothbrush\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the color image\n",
    "# options: IMREAD_COLOR (1), IMREAD_GRAYSCALE (0), IMREAD_UNCHANGED (-1)\n",
    "img = cv2.imread(img_name, cv2.IMREAD_COLOR) # Returns None on bad file\n",
    "dims = img.shape\n",
    "print(\"Image width: {}, height: {}, depth: {}\".format(dims[1], dims[0], dims[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model\n",
    "We instantiate the model from the files loader earlier: `yolov3.weights yolov3.cfg`\n",
    "\n",
    "Then we take a look at some attributes of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNet('yolov3.weights', 'yolov3.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many layers? How many weights overall?\n",
    "names = net.getLayerNames()\n",
    "print(\"Number of layers: \" + str(len(names)))\n",
    "cnt = 0\n",
    "for id in range(1, len(names)) :\n",
    "    layer = net.getLayer(id)\n",
    "    # Each blob is a list of numpy arrays\n",
    "    for blob in layer.blobs :\n",
    "        # multiply the dimensions to get the real number of weights\n",
    "        d = 1\n",
    "        for s in range(len(blob.shape)) :\n",
    "            d = d * blob.shape[s]\n",
    "        cnt = cnt + d\n",
    "\n",
    "print(\"number of weights: \" + str(cnt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the image\n",
    "We convert the `img` numpy array of uint8 and shape (576, 768, 3) to another numpy array of float32 and shape (1, 3, 576, 768).<br/>\n",
    "We then set that `blob` numpy rray as the input to our model.\n",
    "\n",
    "The `scale` value is a multiplier for the values in the array. The value is roughly **1 / 255**. This way, all the values should be smaller or equal to one. Small values are better for neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale=0.00392\n",
    "scale = 1./255.\n",
    "dims = img.shape\n",
    "# blobFromImage(image, scale, (Width,Height), (0,0,0), True, crop=False)\n",
    "blob = cv2.dnn.blobFromImage(img, scale, (dims[1], dims[0]), (0,0,0), True, crop=False)\n",
    "\n",
    "# Set the input to the model\n",
    "net.setInput(blob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "The `get_output_layers` function gets the names of the output layers.\n",
    "\n",
    "The `draw_bounding_boxes` draws bounding boxes around the objects detected. It also display the class of the object.<br/>\n",
    "Since there are 80 classes, we could have used the `COLORS` variable to have random colors assigned to each class. I decided to hardcode the colors. No color were perfect in displaying all the classes names found. I left the different colors that I tried as comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLORS = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "\n",
    "def get_output_layers(net):\n",
    "    layer_names = net.getLayerNames()\n",
    "    output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    return output_layers\n",
    "\n",
    "# function to draw bounding box on the detected object with class name\n",
    "def draw_bounding_box(img, class_id, confidence, x, y, x_plus_w, y_plus_h):\n",
    "    label = str(classes[class_id])\n",
    "    # color = COLORS[class_id]\n",
    "    color1 = np.array([0.0,0.0,255.]) # red\n",
    "    #color2 = np.array([0.0,211.0,255.0]) # Yellow\n",
    "    #color2 = np.array([255.0,128.0,0.0]) # Blue\n",
    "    #color2 = np.array([0.0,0.0,0.0]) # Black\n",
    "    color2 = np.array([0.0,255.0,255.0])# Other yellow\n",
    "    # color2 = np.array([0.0,0.0,128.0]) # Maroon\n",
    "    #color2 = np.array([255.0,255.0,0.0]) # Cyan\n",
    "    #color2 = np.array([255.0,0.0,255.0]) # Magenta\n",
    "    #color2 = np.array([128.0,0.0,128.0]) # Purple\n",
    "    # cv2.rectangle(img, (x,y), (x_plus_w,y_plus_h), color, 2)\n",
    "    cv2.rectangle(img, (x,y), (x_plus_w,y_plus_h), color1, 2)\n",
    "    # cv2.putText(img, label, (x-10,y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "    cv2.putText(img, label, (x-10,y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the objects and bounding boxes\n",
    "The `forward()` method computed the output of the output layers.<br/>\n",
    "Out of these outputs, we find the most likely class. If it has a confidence level higher than 50%, we use it.\n",
    "\n",
    "The output includes the position of the object and its width and heights as a fraction of the original width and size. \n",
    "This way we can easily create a bounding box for the object.\n",
    "\n",
    "We collect all the information into lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run inference through the network and gather predictions from output layers\n",
    "outs = net.forward(get_output_layers(net))\n",
    "# input image shape (dims=img.shape)\n",
    "Width=dims[1]\n",
    "Height=dims[0]\n",
    "\n",
    "# initialization\n",
    "class_ids = []\n",
    "confidences = []\n",
    "boxes = []\n",
    "conf_threshold = 0.5\n",
    "nms_threshold = 0.4\n",
    "\n",
    "# for each detection from each output layer, get the confidence, class id, bounding box params\n",
    "# and ignore weak detections (confidence < 0.5)\n",
    "for out in outs:\n",
    "    for detection in out:\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "        if confidence > 0.5:\n",
    "            center_x = int(detection[0] * Width)\n",
    "            center_y = int(detection[1] * Height)\n",
    "            w = int(detection[2] * Width)\n",
    "            h = int(detection[3] * Height)\n",
    "            x = center_x - w / 2\n",
    "            y = center_y - h / 2\n",
    "            class_ids.append(class_id)\n",
    "            confidences.append(float(confidence))\n",
    "            boxes.append([x, y, w, h])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classes found: \" + str(class_ids))\n",
    "print(\"Classes names: \" + str([classes[i] for i in class_ids]) )\n",
    "print(\"Classes confidence: \" + str(confidences))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawing bounding boxes\n",
    "The `NMSBoxes()` method makes sure the proper boxes are selected based on confidence and are then drawn on the image.\n",
    "\n",
    "The function `draw_bounding_box()` uses the `rectangle()` and the `putText()` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply non-max suppression\n",
    "indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "\n",
    "# go through the detections remaining\n",
    "# after nms and draw bounding box\n",
    "for i in indices:\n",
    "    i = i[0]\n",
    "    box = boxes[i]\n",
    "    x = box[0]\n",
    "    y = box[1]\n",
    "    w = box[2]\n",
    "    h = box[3]\n",
    "    \n",
    "    draw_bounding_box(img, class_ids[i], confidences[i], round(x), round(y), round(x+w), round(y+h))\n",
    "\n",
    "# save output image to disk\n",
    "cv2.imwrite(\"object-detection.jpg\", img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "img = plt.imread('object-detection.jpg')\n",
    "plt.axis('off')\n",
    "plt.title('image')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
